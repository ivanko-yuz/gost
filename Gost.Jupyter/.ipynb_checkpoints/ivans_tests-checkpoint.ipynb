{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfname = pd.read_csv('data_tittles.csv', sep=',', header=None)\n",
    "dfname.columns = [\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgenre = pd.read_csv('data_styles.csv', sep=',', header=None)\n",
    "dfgenre.columns = ['Genre']\n",
    "dfgenre['Genre'] = dfgenre['Genre'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfauthor = pd.read_csv('data_authors.csv', sep=',', header=None)\n",
    "dfauthor.columns = [\"Author\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfhashes = pd.read_csv('data.csv', sep=',', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat([dfhashes,dfauthor,dfname,dfgenre] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full=df_full.fillna(0)\n",
    "dfhashes=dfhashes.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Input, Activation, Dense, BatchNormalization,Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint,Callback\n",
    "import keras.backend as K\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 10430)             54402880  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 52155     \n",
      "=================================================================\n",
      "Total params: 54,455,035\n",
      "Trainable params: 54,455,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=5215*2, activation='sigmoid', input_dim=5215))\n",
    "#model.add(Dense(units=1000, activation='sigmoid'))\n",
    "\n",
    "#model.add(Dropout(0.1))\n",
    "model.add(Dense(units=5, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, momentum=0.9, decay=0, nesterov=True)\n",
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genreToVector(genre):\n",
    "    genres = ['POP', 'CLASSIC', 'UNKNOWN', 'ROCK', 'Metal']\n",
    "    vector = [0] * len(genres)\n",
    "    vector[genres.index(genre)] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorToGenre(vector):\n",
    "    genres = ['POP', 'CLASSIC', 'UNKNOWN', 'ROCK', 'Metal']\n",
    "    genre = genres[np.where(vector==1)[0][0]]\n",
    "    return genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_str = np.array(df_full['Genre'])\n",
    "y_train = np.array(list(map(genreToVector, y_train_str)))\n",
    "\n",
    "x_train_nonorm = np.array(dfhashes)\n",
    "x_train = [0]*len(x_train_nonorm)\n",
    "\n",
    "for i in range(len(x_train_nonorm)):\n",
    "    x_train[i] = x_train_nonorm[i]/float(max(x_train_nonorm[i]))\n",
    "     \n",
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "71/71 [==============================] - 12s 172ms/step - loss: 9.1031 - acc: 0.3521\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 12s 166ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 11s 161ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 11s 157ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 11s 157ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 11s 157ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 11s 157ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 12s 174ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 12s 168ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 11s 157ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 11s 161ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 11s 159ms/step - loss: 10.2157 - acc: 0.3662\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 10.2157 - acc: 0.3662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b19caea6d8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#earlystop = keras.callbacks.EarlyStopping(monitor='loss', min_delta=1e-5, patience=5, verbose=1, mode='auto')\n",
    "model.fit(x_train, y_train, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/71 [==============================] - 2s 29ms/step\n",
      "[10.215694309959948, 0.36619718309859156]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_train, y_train, batch_size=1)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "CLASSIC\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "UNKNOWN\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "Metal\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "CLASSIC\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "CLASSIC\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "CLASSIC\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "CLASSIC\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "CLASSIC\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "CLASSIC\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "CLASSIC\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "ROCK\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "True\n",
      "\n",
      "CLASSIC\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "Metal\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "CLASSIC\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "Metal\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "UNKNOWN\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n",
      "POP\n",
      "[[0. 0. 0. 1. 0.]]\n",
      "ROCK\n",
      "False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_t = 0\n",
    "count_f = 0\n",
    "\n",
    "for line in range(0,71):\n",
    "    print(dfgenre.iloc[[line]].values[0][0])\n",
    "    classes = model.predict(np.array(dfhashes.iloc[[line]]))\n",
    "    print(classes)\n",
    "    vector = np.zeros(5)\n",
    "    vector[np.where(classes == max(max(classes)))[1][0]] = 1\n",
    "    print(vectorToGenre(vector))\n",
    "    \n",
    "    if vectorToGenre(vector) == dfgenre.iloc[[line]].values[0][0]:\n",
    "        print('True')\n",
    "        count_t += 1  \n",
    "    else :\n",
    "        print('False')\n",
    "        count_f += 1\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of true : 26\n",
      "# of false : 45\n"
     ]
    }
   ],
   "source": [
    "print('# of true : ' + str(count_t))\n",
    "print('# of false : ' + str(count_f)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christina Perri - A Thousand Years and genre of song is POP\n"
     ]
    }
   ],
   "source": [
    "i_love_this_song = df_full.iloc[6][1000:2000]\n",
    "print(str(df_full.iloc[6]['Author']) +' - '+ str(df_full.iloc[6]['Title']) +'and genre of song is '+  str(df_full.iloc[6]['Genre']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subfinder(mylist, pattern):\n",
    "    result = []\n",
    "    ansv = False\n",
    "    for i in range(0,len(mylist)):   \n",
    "        print('Checking the {0} song for similar interval'.format(i))\n",
    "        for j in range(len(mylist.iloc[i]) - len(pattern)):            \n",
    "            if list(pattern) == list(mylist.iloc[i][j:j + len(pattern)]):\n",
    "                 ansv = True\n",
    "        if ansv == True:\n",
    "            result.append(mylist.iloc[i])\n",
    "            ansv = False\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the 0 song for similar interval\n",
      "Checking the 1 song for similar interval\n",
      "Checking the 2 song for similar interval\n",
      "Checking the 3 song for similar interval\n",
      "Checking the 4 song for similar interval\n",
      "Checking the 5 song for similar interval\n",
      "Checking the 6 song for similar interval\n"
     ]
    }
   ],
   "source": [
    "ans = subfinder(df_full, df_full.iloc[6][1000:2000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christina Perri - A Thousand Years and genre of song is POP\n"
     ]
    }
   ],
   "source": [
    "ans = pd.DataFrame(ans)\n",
    "print(str(ans['Author'].values[0]) +' - '+ str(ans['Title'].values[0]) +'and genre of song is '+  str(ans['Genre'].values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
